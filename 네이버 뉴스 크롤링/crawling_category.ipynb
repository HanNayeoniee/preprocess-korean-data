{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8c10a50",
   "metadata": {},
   "source": [
    "- 원본 데이터: newsdata/\n",
    "    - ‘Content’ 컬럼: 뉴스 본문 원본 그대로\n",
    "    - ‘Content_split’ 컬럼: ‘Content’ 컬럼 데이터를 kss 라이브러리로 문장 분리한 결과입니다.\n",
    "- 전처리 이후 데이터: preprocessed_data/\n",
    "    - ‘Sent’ 컬럼이 전처리 이후 기사 본문이고, 나머지는 기사 제목, 랭킹, 조회수 등 메타데이터입니다.\n",
    "    - 언론사별 상위 20개씩 정렬되어있습니다. (ex. MBC 1-20위 기사 -> KBS 1-20위 기사 -> SBS 1-20위 기사)\n",
    "    - 넉넉하게 8/1 ~ 10/13 기간 동안 방송 3사의 상위 20개 기사를 수집했습니다. 총 74개의 파일, (31+30+13)x20x3=4440개의 기사입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### kss: 문장 분리에 사용\n",
    "### newspaper3k: 뉴스 기사 크롤링에 사용\n",
    "\n",
    "# !pip install kss\n",
    "# !pip install newspaper3k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36b45e47",
   "metadata": {},
   "source": [
    "## 1. 네이버 뉴스 크롤링 - 기사 분야별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85394d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import kss\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "def get_href(soup):\n",
    "    # 각 분야별 속보 기사에 접근할 수 있는 href를 리스트로 반환\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    div = soup.find(\"div\", class_=\"list_body newsflash_body\")\n",
    "    \n",
    "    for dt in div.find_all(\"dt\", class_=\"photo\"):\n",
    "        result.append(dt.find(\"a\")[\"href\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881129e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_href_daily(section, date):\n",
    "    custom_header = {\n",
    "        'referer' : 'https://www.naver.com/',\n",
    "        'user-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'\n",
    "    }\n",
    "    # https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid2=245&sid1=103&date=20220801\n",
    "    url = \"https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid2=245&sid1=\" + str(section) + \"&date=\" + str(date)\n",
    "    req = requests.get(url, headers=custom_header)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    list_href = get_href(soup)\n",
    "    \n",
    "    return list_href\n",
    "\n",
    "\n",
    "def crawl_daily(news_list, date, save_path):\n",
    "    dates = [str(date)] * len(news_list)\n",
    "    ids = [str(i) for i in range(len(news_list))]\n",
    "\n",
    "    titles = []\n",
    "    contents = []\n",
    "    for news_url in news_list:\n",
    "        article = Article(news_url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        title = article.title\n",
    "        content = article.text.split('\\n')\n",
    "        titles.append(title)\n",
    "        contents.append(content)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame({'date': dates,\n",
    "                       'id': ids,\n",
    "                       'title': titles,\n",
    "                       'content': contents,\n",
    "                       'url': news_list\n",
    "                      })\n",
    "    \n",
    "    out_path = os.path.join(save_path, str(date) + '.json')\n",
    "    df.to_json(out_path, orient='table', index=False, force_ascii=False, indent=4)\n",
    "    print('Saved to: ', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a139569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221001.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221002.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221003.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221004.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221005.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221006.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221007.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221008.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221009.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221010.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221011.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221012.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221013.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221014.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221015.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221016.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221017.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221018.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221019.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221020.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221021.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221022.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221023.json\n",
      "Saved to:  /workspace/chitchat_cb/newsdata_culture/20221024.json\n"
     ]
    }
   ],
   "source": [
    "# {'정치': 100, '경제': 101, '사회': 102, '생활/문화': 103, '세계': 104, 'IT/과학': 105}\n",
    "\n",
    "# test\n",
    "# section = 103\n",
    "# date = 20220801\n",
    "# days = 3\n",
    "# save_path = '/workspace/chitchat_cb/test'\n",
    "\n",
    "\n",
    "section = 103\n",
    "\n",
    "### 8월\n",
    "# date = 20220801\n",
    "# days = 31\n",
    "\n",
    "### 9월\n",
    "# date = 20220901\n",
    "# days = 30\n",
    "\n",
    "### 10월\n",
    "date = 20221001\n",
    "days = 24\n",
    "\n",
    "\n",
    "save_path = '/workspace/chitchat_cb/newsdata_culture'\n",
    "\n",
    "for _ in range(days):\n",
    "    news_list = get_href_daily(section, date)\n",
    "    crawl_daily(news_list, date, save_path)\n",
    "    date += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af27fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde99870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42429a6",
   "metadata": {},
   "source": [
    "## 2. 전처리\n",
    "- [참고 코드](https://github.com/HanNayeoniee/boostcamp/blob/main/week10-KLUE/(2%EA%B0%95)%20%EC%9E%90%EC%97%B0%EC%96%B4%EC%9D%98%20%EC%A0%84%EC%B2%98%EB%A6%AC%20-%200_%ED%95%9C%EA%B5%AD%EC%96%B4%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb)\n",
    "- private repo이므로 권한 요청하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2306494",
   "metadata": {},
   "outputs": [],
   "source": [
    "### kss 라이브러리 사용해 문장 분리\n",
    "def split_sentence(data):\n",
    "    sents = []\n",
    "    for sent in data:\n",
    "        split_sent = kss.split_sentences(sent)\n",
    "        sents.extend(split_sent)\n",
    "\n",
    "    return sents\n",
    "\n",
    "\n",
    "def remove_pattern(texts):\n",
    "    outs = []\n",
    "    p1 = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')  # 이메일(영어@영어)\n",
    "    p2 = re.compile(r'@[\\w\\.-]+')  # (@영어)\n",
    "    p3 = re.compile('\\d{2,3}-\\d{3,4}-\\d{4}$')  # 일반 전화번호\n",
    "    p4 = re.compile('\\d{3}-\\d{3,4}-\\d{4}$')  # 휴대폰번호\n",
    "    p5 = re.compile('^◀')\n",
    "    p6 = re.compile('^▷')\n",
    "    p7 = re.compile('^=')\n",
    "    p8 = re.compile('^MBC뉴스')\n",
    "    p9 = re.compile('^영상제공 : ')\n",
    "    # kbs\n",
    "    p10 = re.compile('^KBS 뉴스')\n",
    "    p11 = re.compile('^영상편집:')\n",
    "    p12 = re.compile('^촬영기자:')\n",
    "    p13 = re.compile('^\\(영상취재 :')\n",
    "    \n",
    "\n",
    "    for text in texts:    \n",
    "        res1 = p1.findall(text)\n",
    "        res2 = p2.findall(text)\n",
    "        res3 = p3.findall(text)\n",
    "        res4 = p4.findall(text)\n",
    "        res5 = p5.findall(text)\n",
    "        res6 = p6.findall(text)\n",
    "        res7 = p7.findall(text)\n",
    "        res8 = p8.findall(text)\n",
    "        res9 = p9.findall(text)\n",
    "        res10 = p10.findall(text)\n",
    "        res11 = p11.findall(text)\n",
    "        res12 = p12.findall(text)\n",
    "        res13 = p13.findall(text)\n",
    "        \n",
    "        if not res1 and not res2 and not res3 and not res4 and not res5 and not res6 and not res7 and not res8 \\\n",
    "            and not res9 and not res10 and not res11 and not res12 and not res13:\n",
    "            outs.append(text)\n",
    "\n",
    "    return outs\n",
    "\n",
    "\n",
    "def remove_stops(texts):\n",
    "    outs = []\n",
    "    stop_mbc = ['MBC 뉴스는 24시간 여러분의 제보를 기다립니다.', '[뉴스투데이]', '[탐사기획 스트레이트]']\n",
    "    \n",
    "    for text in texts:    \n",
    "        if text not in stop_mbc:\n",
    "            outs.append(text)\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e25ddf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_press(texts):\n",
    "    patterns = [r\"\\(사진=[가-힣]{3,4}\\)$\",  # (사진=연합뉴스)\n",
    "                    r\"\\(사진=[가-힣]{3,4} [가-힣]{3,4}\\)$\",  # (사진=온라인 커뮤니티)\n",
    "                    r\"(촬영기자:|영상편집:|그래픽:|영상취재:|편집:)[가-힣]{2,4}\",  # 촬영기자:윤대민/영상편집:최근혁/그래픽:김석훈\n",
    "                    r\"(촬영기자: |영상편집: |그래픽: |영상취재: |편집: )[가-힣]{2,4}\",  # 촬영기자: 윤대민/영상편집: 최근혁/그래픽: 김석훈\n",
    "                    r\"(영상취재|영상편집|그래픽|영상취재|편집)·(영상취재|영상편집|그래픽|영상취재|편집): [가-힣]{2,4}\",  # 영상취재·편집: 위동원 \n",
    "                    r\"(영상취재|영상편집|그래픽|영상취재|편집)·(영상취재|영상편집|그래픽|영상취재|편집):[가-힣]{2,4}\",  # 영상취재·편집:위동원 \n",
    "                    r\"\\((영상취재 : |영상편집 : |그래픽 : |편집: )[가-힣]{2,4}·[가-힣]{2,4}\", # (영상취재 : 김균종·조창현\n",
    "                    r\"(영상취재 : |영상편집 : |그래픽 : |편집 : \\))[가-힣]{2,4}\",  # 영상편집 : 박지인\n",
    "                    r\"\\((영상취재 : |영상편집 : |그래픽 : |편집 : \\))[가-힣]{2,4}\",  # (영상편집 : 박지인\n",
    "                    r\"\\[탐사기획 스트레이트]\",\n",
    "                    r\"\\[설문 참여하기]\",\n",
    "                    r\"<기자>\",\n",
    "                    r\"<앵커>\",\n",
    "                    r\"앵커>\"\n",
    "                    ]\n",
    "    \n",
    "    outs = []\n",
    "    for text in texts:\n",
    "        for pat in patterns:\n",
    "            text = re.sub(pat, \"\", text).strip()\n",
    "        if text:\n",
    "            outs.append(text)    \n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9306ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(texts):\n",
    "    \"\"\"\n",
    "    URL을 제거합니다.\n",
    "    ``주소: www.naver.com`` -> ``주소: ``\n",
    "    \"\"\"\n",
    "    outs = []\n",
    "    for text in texts:\n",
    "        text = re.sub(r\"(http|https)?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"\", text).strip()\n",
    "        text = re.sub(r\"pic\\.(\\w+\\.)+\\S*\", \"\", text).strip()\n",
    "        if text:\n",
    "            outs.append(text)\n",
    "    return outs\n",
    "\n",
    "\n",
    "def filter(texts):\n",
    "    outs = []\n",
    "    for text in texts:\n",
    "        text = re.sub('[▲━■▶◀△☎■▲※🎧]', '', text)\n",
    "        if text:\n",
    "            outs.append(text)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e39aae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json파일 개수: 85\n",
      "Save to: ./newsdata_culture_res/20220815.json\n",
      "Save to: ./newsdata_culture_res/20220822.json\n",
      "Save to: ./newsdata_culture_res/20221012.json\n",
      "Save to: ./newsdata_culture_res/20220804.json\n",
      "Save to: ./newsdata_culture_res/20221008.json\n",
      "Save to: ./newsdata_culture_res/20220910.json\n",
      "Save to: ./newsdata_culture_res/20220823.json\n",
      "Save to: ./newsdata_culture_res/20220814.json\n",
      "Save to: ./newsdata_culture_res/20220912.json\n",
      "Save to: ./newsdata_culture_res/20221010.json\n",
      "Save to: ./newsdata_culture_res/20220830.json\n",
      "Save to: ./newsdata_culture_res/20220827.json\n",
      "Save to: ./newsdata_culture_res/20220922.json\n",
      "Save to: ./newsdata_culture_res/20221024.json\n",
      "Save to: ./newsdata_culture_res/20220802.json\n",
      "Save to: ./newsdata_culture_res/20220909.json\n",
      "Save to: ./newsdata_culture_res/20220803.json\n",
      "Save to: ./newsdata_culture_res/20220923.json\n",
      "Save to: ./newsdata_culture_res/20220806.json\n",
      "Save to: ./newsdata_culture_res/20220927.json\n",
      "Save to: ./newsdata_culture_res/20220810.json\n",
      "Save to: ./newsdata_culture_res/20221021.json\n",
      "Save to: ./newsdata_culture_res/20220920.json\n",
      "Save to: ./newsdata_culture_res/20221002.json\n",
      "Save to: ./newsdata_culture_res/20220824.json\n",
      "Save to: ./newsdata_culture_res/20221006.json\n",
      "Save to: ./newsdata_culture_res/20220813.json\n",
      "Save to: ./newsdata_culture_res/20220819.json\n",
      "Save to: ./newsdata_culture_res/20220924.json\n",
      "Save to: ./newsdata_culture_res/20221001.json\n",
      "Save to: ./newsdata_culture_res/20221009.json\n",
      "Save to: ./newsdata_culture_res/20221013.json\n",
      "Save to: ./newsdata_culture_res/20220811.json\n",
      "Save to: ./newsdata_culture_res/20220816.json\n",
      "Save to: ./newsdata_culture_res/20220809.json\n",
      "Save to: ./newsdata_culture_res/20220903.json\n",
      "Save to: ./newsdata_culture_res/20221020.json\n",
      "Save to: ./newsdata_culture_res/20220907.json\n",
      "Save to: ./newsdata_culture_res/20220807.json\n",
      "Save to: ./newsdata_culture_res/20220919.json\n",
      "Save to: ./newsdata_culture_res/20220825.json\n",
      "Save to: ./newsdata_culture_res/20221017.json\n",
      "Save to: ./newsdata_culture_res/20221023.json\n",
      "Save to: ./newsdata_culture_res/20220918.json\n",
      "Save to: ./newsdata_culture_res/20221018.json\n",
      "Save to: ./newsdata_culture_res/20220915.json\n",
      "Save to: ./newsdata_culture_res/20221003.json\n",
      "Save to: ./newsdata_culture_res/20220921.json\n",
      "Save to: ./newsdata_culture_res/20220908.json\n",
      "Save to: ./newsdata_culture_res/20221007.json\n",
      "Save to: ./newsdata_culture_res/20221005.json\n",
      "Save to: ./newsdata_culture_res/20220821.json\n",
      "Save to: ./newsdata_culture_res/20221004.json\n",
      "Save to: ./newsdata_culture_res/20220904.json\n",
      "Save to: ./newsdata_culture_res/20220829.json\n",
      "Save to: ./newsdata_culture_res/20220928.json\n",
      "Save to: ./newsdata_culture_res/20220913.json\n",
      "Save to: ./newsdata_culture_res/20221016.json\n",
      "Save to: ./newsdata_culture_res/20220926.json\n",
      "Save to: ./newsdata_culture_res/20220826.json\n",
      "Save to: ./newsdata_culture_res/20220914.json\n",
      "Save to: ./newsdata_culture_res/20220817.json\n",
      "Save to: ./newsdata_culture_res/20220808.json\n",
      "Save to: ./newsdata_culture_res/20221011.json\n",
      "Save to: ./newsdata_culture_res/20221022.json\n",
      "Save to: ./newsdata_culture_res/20220805.json\n",
      "Save to: ./newsdata_culture_res/20220930.json\n",
      "Save to: ./newsdata_culture_res/20220831.json\n",
      "Save to: ./newsdata_culture_res/20221014.json\n",
      "Save to: ./newsdata_culture_res/20220801.json\n",
      "Save to: ./newsdata_culture_res/20220818.json\n",
      "Save to: ./newsdata_culture_res/20220906.json\n",
      "Save to: ./newsdata_culture_res/20220916.json\n",
      "Save to: ./newsdata_culture_res/20220901.json\n",
      "Save to: ./newsdata_culture_res/20220917.json\n",
      "Save to: ./newsdata_culture_res/20220925.json\n",
      "Save to: ./newsdata_culture_res/20220828.json\n",
      "Save to: ./newsdata_culture_res/20220812.json\n",
      "Save to: ./newsdata_culture_res/20220820.json\n",
      "Save to: ./newsdata_culture_res/20220929.json\n",
      "Save to: ./newsdata_culture_res/20220902.json\n",
      "Save to: ./newsdata_culture_res/20221015.json\n",
      "Save to: ./newsdata_culture_res/20220911.json\n",
      "Save to: ./newsdata_culture_res/20220905.json\n",
      "Save to: ./newsdata_culture_res/20221019.json\n"
     ]
    }
   ],
   "source": [
    "## 모든 파일에 대해 전처리 수행\n",
    "\n",
    "target = './newsdata_culture/*.json'\n",
    "json_list = glob.glob(target)\n",
    "print('json파일 개수:', len(json_list))\n",
    "\n",
    "\n",
    "for file in json_list:\n",
    "    with open(file, 'r') as f:\n",
    "        json_data = json.load(f)[\"data\"]\n",
    "        df = pd.DataFrame(json_data)\n",
    "\n",
    "\n",
    "        sents = []\n",
    "        for data in df[\"content\"]:\n",
    "            split_sent = split_sentence(data)\n",
    "#             print('문장 개수:', len(split_sent))\n",
    "            outs = remove_pattern(split_sent)\n",
    "            outs = remove_stops(outs)\n",
    "            outs = remove_press(outs)\n",
    "            outs = remove_url(outs)\n",
    "            outs = filter(outs)        \n",
    "            sents.append(split_sent)\n",
    "\n",
    "    df['sent'] = sents\n",
    "    save_path = os.path.join('./newsdata_culture_res/', Path(file).stem + '.json')\n",
    "    df.to_json(save_path, orient='table', index=False, force_ascii=False, indent=4)\n",
    "    print('Save to:', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fac5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "\n",
    "\n",
    "## 모든 파일에 대해 전처리 수행\n",
    "\n",
    "target = './newsdata_culture_res/*.json'\n",
    "json_list = glob.glob(target)\n",
    "json_list = natsort.natsorted(json_list)\n",
    "print('json파일 개수:', len(json_list))\n",
    "\n",
    "\n",
    "start_file = json_list[0]\n",
    "with open(start_file, 'r') as f:\n",
    "    json_data = json.load(f)[\"data\"]\n",
    "    df = pd.DataFrame(json_data)\n",
    "    news_id = [df['date'][i] + '_' + str(df['id'][i]) for i in range(len(df))]\n",
    "    df['news_id'] = news_id\n",
    "    total_df = df[['news_id', 'url', 'title', 'sent']]\n",
    "\n",
    "\n",
    "for file in json_list[1:]:\n",
    "    with open(file, 'r') as f:\n",
    "        json_data = json.load(f)[\"data\"]\n",
    "        df = pd.DataFrame(json_data)\n",
    "        news_id = [df['date'][i] + '_' + str(df['id'][i]) for i in range(len(df))]\n",
    "        df['news_id'] = news_id\n",
    "        df = df[['news_id', 'url', 'title', 'sent']]\n",
    "    total_df = pd.concat([total_df, df])\n",
    "\n",
    "    \n",
    "total_df.to_excel('./final.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bcbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
